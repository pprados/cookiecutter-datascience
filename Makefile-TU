#!/usr/bin/env make

# This is a unit test of all target of generated Makefile
# Use a temporay coTS = -e -c
SHELL=/bin/bash
.SHELLFLAGS = -e -c
.ONESHELL:

ifeq ($(shell echo "$(MAKE_VERSION) >= 4" | bc -l),0)
$(error Bad make version, please install make >= 4)
endif

ifeq ($(OFFLINE),True)
export CONDA_ARGS=--use-index-cache --use-local --offline
else
export CONDA_ARGS=--use-index-cache --use-local
endif

export NPROC?=$(shell nproc)
# Ne fonctionne pas en parallelisant les make du build. (et j'ai pas testé)
#MAKE_PARALLEL?=-j $(NPROC)
MAKE_PARALLEL?=


PYTHON_VERSION=3.6
CONDA_BASE=$(shell conda info --base)
CONDA_PACKAGE:=$(CONDA_PREFIX)/lib/python$(PYTHON_VERSION)/site-packages
CONDA_PYTHON:=$(CONDA_PREFIX)/bin/python

ifndef NLTK_DATA
export NTLK_DATA
# La ligne suivante ralenti le Makefile. A activer qu'avec des env. spécifiques.
#NLTK_DATA:=$(shell python -c "import nltk.data; print(nltk.data.path[0])" 2>/dev/null || true)
# Sinon, utiliser le code suivant
ifeq ($(OS),Darwin)
ifeq ($(wildcard ~/nltk_data), )
NLTK_DATA=/usr/local/share/nltk_data
else
NLTK_DATA=~/nltk_data
endif
else ifeq ($(OS),Windows)
NLTK_DATA=C:/nltk_data
else
ifeq ($(wildcard ~/nltk_data), )
NLTK_DATA=/usr/share/nltk_data
else
NLTK_DATA=~/nltk_data
endif
endif
endif

.PHONY: dump-*
dump-%:
	@if [ "${${*}}" = "" ]; then
		echo "Environment variable $* is not set";
		exit 1;
	else
		echo "$*=${${*}}";
	fi

# Create a temporary VENV and DATA
# Warning, it's not a realy isolated environment with MT because, dist, etc
# are not cleaning. May be, duplicate all the project ?
define do_make
	@echo ""
    @echo "---------------------------- $$TU - $1 ---------------------------- "
    set -e
	V=CC_temp_$(shell cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 10 | head -n 1)
	D=/tmp/$$V
	export NLTK_DATA=$${D}_nltk_data
	mkdir $$NLTK_DATA
	cp -Rf . $$D/
	oldpath=`pwd`
	cd $$D/
    echo "$1"> test.txt
	. $(CONDA_BASE)/etc/profile.d/conda.sh
	conda create $$CONDA_ARGS -n $$V -y python=$(PYTHON_VERSION)
	conda activate $$V
	# PPR est-ce util d'ajouter le pip install setuptools_scm ?
	pip install $(PIP_ARGS) setuptools_scm
	rm -rf data/interim/* data/processed/* data/external/*
	CONDA_PACKAGE=$${CONDA_PREFIX}/lib/python$(PYTHON_VERSION)/site-packages
	export EC2_LIFE_CYCLE=--terminate
	export S3_BUCKET=s3://pprados
	export SPACY_DATABASE="$${CONDA_PACKAGE}/spacy/data/en"
	export NLTK_DATABASE="$${NLTK_DATA}/corpora/wordnet $${NLTK_DATA}/tokenizers/punkt $${NLTK_DATA}/corpora/stopwords"
	export KERNEL=bda_project
	mkdir -p $${NLTK_DATABASE} $${SPACY_DATABASE}
	echo ""
    echo "---- $$TU - $1"
	echo "cd $$(pwd)"
	echo "conda activate $$V"
	echo "VENV=$$V $(MAKE) $(MAKE_PARALLEL) $1"
	cd "$$oldpath"
	conda deactivate
	conda env remove -n $$V 2>/dev/null
	# PPR bug avec DVC si je rm ?
	#rm -Rf $$D
endef

.PHONY: help
.DEFAULT: help
help:
	$(call do_make,help)

.PHONY: dump
dump:
	$(call do_make,dump-CONDA_BASE)

.PHONY: .git
.git:
	$(call do_make,.git)

.PHONY: .gitattributes
.gitattributes:
	$(call do_make,.gitattributes)

.PHONY: requirements
requirements:
	$(call do_make,requirements)

.PHONY: dependencies
dependencies:
	$(call do_make,dependencies)

.PHONY: NLTK
NLTK:
	$(call do_make,$${NLTK_DATA}/corpora/wordnet)
	$(call do_make,$${NLTK_DATA}/tokenizers/punkt)
	$(call do_make,$${NLTK_DATA}/corpora/stopwords)
	echo empty

.PHONY: spacy

spacy:
	 $(call do_make,$${CONDA_PACKAGE}/spacy/data/en)

.PHONY: configure
configure:
	$(call do_make,configure)

.PHONY: remove-venv
remove-venv:
	$(call do_make,remove-venv)

.PHONY: upgrade-venv
upgrade-venv:
	$(call do_make,upgrade-venv)

.PHONY: run
run:
	$(call do_make,run-phase1)

.PHONY: lint
lint:
	$(call do_make,lint)

.PHONY: typing
typing:
	$(call do_make,typing)

.PHONY: add-typing
add-typing:
	$(call do_make,typing)
#-------------------
.PHONY: build
build_html:
	$(call do_make,build/html)
build_latexpdf:
	$(call do_make,build/latexpdf)

# PPR BUG in framework latexpdf build: build_html build_latexpdf
build: build_html

#-------------------
.PHONY: remove-kernel
remove-kernel:
	$(call do_make,remove-kernel)


.PHONY: nb-run
nb-run:
	$(call do_make,nb-run-phase1)


.PHONY: notebook
# notebook


.PHONY: nb-convert
nb-convert:
	$(call do_make,nb-convert)

.PHONY: clean-notebooks
clean-notebooks:
	$(call do_make,clean-notebooks)

#-------------------
.PHONY: sdist bdist dist
sdist:
	$(call do_make,sdist)

bdist:
	$(call do_make,bdist)

dist:
	$(call do_make,dist)

#-------------------
.PHONY: release check-twine test-twine
release:
	$(call do_make,release)

check-twine:
	$(call do_make,check-twine)

test-twine:
	$(call do_make,test-twine)
#-------------------
.PHONY: clean-pyc clean-build clean-pip clean-venv clean clean-all
clean-pyc:
	$(call do_make,clean-pyc)

clean-build:
	$(call do_make,clean-build)

clean-pip:
	$(call do_make,clean-pip)

clean-venv:
	$(call do_make,clean-venv)

clean:
	$(call do_make,clean)

clean-all:
	$(call do_make,clean-all)

#-------------------
.PHONY: test unit-test functional-test validate
unit-test:
	$(call do_make,unit-test)

functional-test:
	$(call do_make,functional-test)

test:
	$(call do_make,test)

validate:
	$(call do_make,validate)

#-------------------
.PHONY: sync_to_s3 sync_from_s3
sync_to_s3:
	$(call do_make,sync_to_s3/raw)

sync_from_s3:
	$(call do_make,sync_from_s3/raw)

S3: sync_to_s3 sync_from_s3

#-------------------
.PHONY: dvc-external lock metrics
dvc-external:
	$(call do_make,dvc-external-s3)
lock:
	$(call do_make,features lock-features.dvc)
metrics:
	$(call do_make,evaluate metrics)
DVC:dvc-external lock metrics
#-------------------
# FIXME: S'assurer de bien détruire les instances
ec2:
	$(call do_make,ec2-clean)

ec2-tmux:
	$(call do_make,ec2-tmux-clean ; [ "$$OFFLINE" = True ] || ssh-ec2 --terminate :)
ec2-attach:
	$(call do_make,ec2-detach-clean ec2-attach ; [ "$$OFFLINE" = True ] || ssh-ec2 --terminate :)
ec2-terminate:
	$(call do_make,ec2-detach-clean ec2-terminate)
ec2-notebook:
	$(call do_make,ec2-notebook ; [ "$$OFFLINE" = True ] || ssh-ec2 --terminate :)
EC2: ec2 ec2-tmux ec2-terminate

#-------------------
.PHONY: prepare features train evalutate visualize
prepare:
	$(call do_make,prepare)

features:
	$(call do_make,features)

train:
	$(call do_make,train)

evaluate:
	$(call do_make,evaluate)

visualize:
	$(call do_make,visualize)
#-------------------
# Group services
STD: .git .gitattributes requirements dependencies \
	configure remove-venv
STD_ONLINE: upgrade-venv

DIST: sdist bdist dist
CLEAN: clean-pyc clean-build clean-venv clean clean-all
TEST: test unit-test functional-test validate lint typing add-typing
ML: prepare features train evaluate visualize

#-------------------
# Group of options
NOT_TESTED: clean-pip check-twine test-twine release ec2-attach ec2-notebook docker-*
TEXT_PROCESSING_ONLINE:spacy NLTK
DEFAULT: CLEAN STD DVC DIST TEST ML
DEFAULT_ONLINE: STD_ONLINE
DOCS: build
JUPYTER: remove-kernel nb-run nb-convert add-typing clean-notebooks
AWS_ONLINE: S3 EC2
